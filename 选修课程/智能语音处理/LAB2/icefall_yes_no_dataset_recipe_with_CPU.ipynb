{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC0w8FMdN1j1"
      },
      "source": [
        "# Yesno recipe in icefall\n",
        "\n",
        "This notebook shows you how to setup the environment to use [icefall][icefall] for training and decoding.\n",
        "It also describes how to use a per-trained model to decode waves.\n",
        "\n",
        "\n",
        "We use the [yesno] dataset as an example.\n",
        "\n",
        "[icefall]: https://github.com/k2-fsa/icefall\n",
        "[yesno]: https://www.openslr.org/1/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8jMkYeDQUeY"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etfavk8FQXRQ"
      },
      "source": [
        "### Install PyTorch and torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AliAaueDNteG",
        "outputId": "f456b8ca-ba6e-4375-92cd-37d8d8a20453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.1+cu117\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXyznh4VaZVj"
      },
      "source": [
        "Colab pre-installs PyTorch, so we don't need to install it here.\n",
        "\n",
        "From https://pytorch.org/audio/main/installation.html#compatibility-matrix, we need to install torchaudio==2.0.2 as the current PyTorch version is 2.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJzBhtJAQbD6",
        "outputId": "d1767307-24ff-4b57-e264-1161fddb60be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio==2.0.2) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchaudio==2.0.2) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchaudio==2.0.2) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchaudio==2.0.2) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio==2.0.2) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchaudio==2.0.2) (18.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchaudio==2.0.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchaudio==2.0.2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install torchaudio==2.0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0HY88GiR7_J"
      },
      "source": [
        "### Install k2\n",
        "\n",
        "We are going to install k2 by following https://k2-fsa.github.io/k2/installation/from_wheels.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JccZFPBQ7vJ",
        "outputId": "2a02d8dd-6f58-4cdb-d9a6-cb84e187754b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://k2-fsa.github.io/k2/cuda.html\n",
            "Collecting k2==1.24.3.dev20230718+cuda11.7.torch2.0.1\n",
            "  Downloading https://huggingface.co/csukuangfj/k2/resolve/main/cuda/k2-1.24.3.dev20230718%2Bcuda11.7.torch2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (2.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (18.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->k2==1.24.3.dev20230718+cuda11.7.torch2.0.1) (1.3.0)\n",
            "Installing collected packages: k2\n",
            "  Attempting uninstall: k2\n",
            "    Found existing installation: k2 1.24.3.dev20230718+cuda11.8.torch2.0.1\n",
            "    Uninstalling k2-1.24.3.dev20230718+cuda11.8.torch2.0.1:\n",
            "      Successfully uninstalled k2-1.24.3.dev20230718+cuda11.8.torch2.0.1\n",
            "Successfully installed k2-1.24.3.dev20230718+cuda11.7.torch2.0.1\n"
          ]
        }
      ],
      "source": [
        "! pip install k2==1.24.3.dev20230718+cuda11.7.torch2.0.1 -f https://k2-fsa.github.io/k2/cuda.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference with a pre-trained model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Jl3lHExSTSI"
      },
      "source": [
        "Check that k2 was installed successfully:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYnIIeh6SPz9",
        "outputId": "9fb18d40-9b87-4085-8ce7-6d9df75e7e40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting environment information...\n",
            "\n",
            "k2 version: 1.24.3\n",
            "Build type: Release\n",
            "Git SHA1: e400fa3b456faf8afe0ee5bfe572946b4921a3db\n",
            "Git date: Sat Jul 15 04:21:50 2023\n",
            "Cuda used to build k2: 11.7\n",
            "cuDNN used to build k2: \n",
            "Python version used to build k2: 3.10\n",
            "OS used to build k2: CentOS Linux release 7.9.2009 (Core)\n",
            "CMake version: 3.26.4\n",
            "GCC version: 9.3.1\n",
            "CMAKE_CUDA_FLAGS:  -Wno-deprecated-gpu-targets   -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_35,code=sm_35  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_50,code=sm_50  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_60,code=sm_60  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_61,code=sm_61  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_70,code=sm_70  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_75,code=sm_75  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_80,code=sm_80  -lineinfo --expt-extended-lambda -use_fast_math -Xptxas=-w  --expt-extended-lambda -gencode arch=compute_86,code=sm_86 -DONNX_NAMESPACE=onnx_c2 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_80,code=sm_80 -gencode arch=compute_86,code=sm_86 -gencode arch=compute_86,code=compute_86 -Xcudafe --diag_suppress=cc_clobber_ignored,--diag_suppress=integer_sign_change,--diag_suppress=useless_using_declaration,--diag_suppress=set_but_not_used,--diag_suppress=field_without_dll_interface,--diag_suppress=base_class_has_different_dll_interface,--diag_suppress=dll_interface_conflict_none_assumed,--diag_suppress=dll_interface_conflict_dllexport_assumed,--diag_suppress=implicit_return_from_non_void_function,--diag_suppress=unsigned_compare_with_zero,--diag_suppress=declared_but_not_referenced,--diag_suppress=bad_friend_decl --expt-relaxed-constexpr --expt-extended-lambda -D_GLIBCXX_USE_CXX11_ABI=0 --compiler-options -Wall  --compiler-options -Wno-strict-overflow  --compiler-options -Wno-unknown-pragmas \n",
            "CMAKE_CXX_FLAGS:  -D_GLIBCXX_USE_CXX11_ABI=0 -Wno-unused-variable  -Wno-strict-overflow \n",
            "PyTorch version used to build k2: 2.0.1+cu117\n",
            "PyTorch is using Cuda: 11.7\n",
            "NVTX enabled: True\n",
            "With CUDA: True\n",
            "Disable debug: True\n",
            "Sync kernels : False\n",
            "Disable checks: False\n",
            "Max cpu memory allocate: 214748364800 bytes (or 200.0 GB)\n",
            "k2 abort: False\n",
            "__file__: /usr/local/lib/python3.10/dist-packages/k2/version/version.py\n",
            "_k2.__file__: /usr/local/lib/python3.10/dist-packages/_k2.cpython-310-x86_64-linux-gnu.so\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "! python3 -m k2.version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biN4HMqFSdJ5"
      },
      "source": [
        "### Install lhotse\n",
        "[lhotse][lhotse] is used for data preparation.\n",
        "\n",
        "[lhotse]: https://github.com/lhotse-speech/lhotse\n",
        "\n",
        "Normally, we would use `pip install lhotse`. However, the yesno recipe is added recently and has not been released to PyPI yet, so we install the latest unreleased version here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SsFZwCESWz_",
        "outputId": "31a1e215-6fb2-443d-ed77-3b904a813f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/lhotse-speech/lhotse\n",
            "  Cloning https://github.com/lhotse-speech/lhotse to /tmp/pip-req-build-8zqkao5p\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lhotse-speech/lhotse /tmp/pip-req-build-8zqkao5p\n",
            "  Resolved https://github.com/lhotse-speech/lhotse to commit 1b68036d20e5a674c45c01d7719ddacc2d6742ac\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (3.0.1)\n",
            "Requirement already satisfied: SoundFile>=0.10 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (0.12.1)\n",
            "Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (8.1.7)\n",
            "Collecting cytoolz>=0.10.1 (from lhotse==1.23.0.dev0+git.1b68036.clean)\n",
            "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting intervaltree>=3.1.0 (from lhotse==1.23.0.dev0+git.1b68036.clean)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (6.0.1)\n",
            "Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (0.9.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (4.66.2)\n",
            "Collecting lilcom>=1.1.0 (from lhotse==1.23.0.dev0+git.1b68036.clean)\n",
            "  Downloading lilcom-1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (2.0.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from lhotse==1.23.0.dev0+git.1b68036.clean) (2.0.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse==1.23.0.dev0+git.1b68036.clean) (0.12.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3.1.0->lhotse==1.23.0.dev0+git.1b68036.clean) (2.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10->lhotse==1.23.0.dev0+git.1b68036.clean) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->lhotse==1.23.0.dev0+git.1b68036.clean) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (18.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10->lhotse==1.23.0.dev0+git.1b68036.clean) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->lhotse==1.23.0.dev0+git.1b68036.clean) (1.3.0)\n",
            "Building wheels for collected packages: lhotse, intervaltree\n",
            "  Building wheel for lhotse (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lhotse: filename=lhotse-1.23.0.dev0+git.1b68036.clean-py3-none-any.whl size=770545 sha256=676bf1b85fd8e42df0a8a22a8f3a68538a4cff9e4b1d24e58d00f51eb997ea0d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vkd580ip/wheels/df/b0/ff/cce0f16868fcdbee2088f3acf9f249dc90117d5f5dd9b6f69d\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26096 sha256=ccdb0433b0ab3fe09c93c42d98c2694f82e7be2f0d0137812c8c84f4e1772b9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built lhotse intervaltree\n",
            "Installing collected packages: lilcom, intervaltree, cytoolz, lhotse\n",
            "Successfully installed cytoolz-0.12.3 intervaltree-3.1.0 lhotse-1.23.0.dev0+git.1b68036.clean lilcom-1.7\n"
          ]
        }
      ],
      "source": [
        "# ! pip install lhotse\n",
        "! pip install git+https://github.com/lhotse-speech/lhotse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwq8uAGpSyzu"
      },
      "source": [
        "### Install icefall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ivIXM8FS0Yy"
      },
      "source": [
        "[icefall][icefall] is a collection of Python scripts.\n",
        "You don't need to install it. What you need to do is\n",
        "to get its source code, install its dependencies, and\n",
        "set the `PYTHONPATH` pointing to it.\n",
        "\n",
        "[icefall]: https://github.com/k2-fsa/icefall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aflfLSytSnFe",
        "outputId": "a8bfb1d7-627f-4525-8654-cfb6a40e1610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "! pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP4RZ31xTKzL",
        "outputId": "a5fdd48a-c894-4183-9324-cc22148e2789"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'icefall'...\n",
            "remote: Enumerating objects: 17594, done.\u001b[K\n",
            "remote: Counting objects: 100% (1110/1110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (653/653), done.\u001b[K\n",
            "remote: Total 17594 (delta 594), reused 756 (delta 358), pack-reused 16484\u001b[K\n",
            "Receiving objects: 100% (17594/17594), 18.82 MiB | 18.07 MiB/s, done.\n",
            "Resolving deltas: 100% (11870/11870), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/k2-fsa/icefall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1c5zESwTtii"
      },
      "source": [
        "Now install dependencies of `icefall`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYOwkp6FTrdH",
        "outputId": "46c131ba-c278-4934-d356-95c4ab868831"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaldifst>1.7.0 (from -r requirements.txt (line 1))\n",
            "  Downloading kaldifst-1.7.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaldilm (from -r requirements.txt (line 2))\n",
            "  Downloading kaldilm-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaldialign (from -r requirements.txt (line 3))\n",
            "  Downloading kaldialign-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words (from -r requirements.txt (line 4))\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaldi-decoder (from -r requirements.txt (line 5))\n",
            "  Downloading kaldi_decoder-0.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece>=0.1.96 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.1.99)\n",
            "Collecting pypinyin==0.50.0 (from -r requirements.txt (line 7))\n",
            "  Downloading pypinyin-0.50.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.15.2)\n",
            "Collecting typeguard (from -r requirements.txt (line 9))\n",
            "  Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
            "Collecting dill (from -r requirements.txt (line 10))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.15.0 (from -r requirements.txt (line 11))\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.16.3 (from -r requirements.txt (line 12))\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxoptimizer (from -r requirements.txt (line 13))\n",
            "  Downloading onnxoptimizer-0.3.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (678 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxsim (from -r requirements.txt (line 14))\n",
            "  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==22.3.0 (from -r requirements.txt (line 17))\n",
            "  Downloading black-22.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isort==5.10.1 (from -r requirements.txt (line 18))\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flake8==5.0.4 (from -r requirements.txt (line 19))\n",
            "  Downloading flake8-5.0.4-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycantonese==3.4.0 (from -r requirements.txt (line 22))\n",
            "  Downloading pycantonese-3.4.0-py3-none-any.whl (3.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 17)) (8.1.7)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 17)) (4.2.0)\n",
            "Collecting pathspec>=0.9.0 (from black==22.3.0->-r requirements.txt (line 17))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==22.3.0->-r requirements.txt (line 17))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black==22.3.0->-r requirements.txt (line 17)) (2.0.1)\n",
            "Collecting mccabe<0.8.0,>=0.7.0 (from flake8==5.0.4->-r requirements.txt (line 19))\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.10.0,>=2.9.0 (from flake8==5.0.4->-r requirements.txt (line 19))\n",
            "  Downloading pycodestyle-2.9.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyflakes<2.6.0,>=2.5.0 (from flake8==5.0.4->-r requirements.txt (line 19))\n",
            "  Downloading pyflakes-2.5.0-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylangacq<0.17.0,>=0.16.0 (from pycantonese==3.4.0->-r requirements.txt (line 22))\n",
            "  Downloading pylangacq-0.16.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wordseg==0.0.2 (from pycantonese==3.4.0->-r requirements.txt (line 22))\n",
            "  Downloading wordseg-0.0.2-py3-none-any.whl (9.5 kB)\n",
            "Collecting docopt>=0.6.2 (from num2words->-r requirements.txt (line 4))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from typeguard->-r requirements.txt (line 9)) (4.11.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.16.3->-r requirements.txt (line 12))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.3->-r requirements.txt (line 12)) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.3->-r requirements.txt (line 12)) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.16.3->-r requirements.txt (line 12)) (1.12)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim->-r requirements.txt (line 14)) (13.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil<=3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pylangacq<0.17.0,>=0.16.0->pycantonese==3.4.0->-r requirements.txt (line 22)) (2.8.2)\n",
            "Requirement already satisfied: tabulate[widechars]<=0.9.0,>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from pylangacq<0.17.0,>=0.16.0->pycantonese==3.4.0->-r requirements.txt (line 22)) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 8)) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 8)) (2.1.5)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.16.3->-r requirements.txt (line 12))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim->-r requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim->-r requirements.txt (line 14)) (2.16.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.16.3->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim->-r requirements.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 8)) (3.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from tabulate[widechars]<=0.9.0,>=0.8.9->pylangacq<0.17.0,>=0.16.0->pycantonese==3.4.0->-r requirements.txt (line 22)) (0.2.13)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8cf5f2ccf3f5aa709b4de269c75bd87d3278efe429d2baece0dad2dc9b7b37d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: kaldilm, kaldifst, kaldialign, docopt, wordseg, typeguard, pypinyin, pyflakes, pycodestyle, pathspec, onnx, num2words, mypy-extensions, mccabe, kaldi-decoder, isort, humanfriendly, dill, pylangacq, onnxoptimizer, flake8, coloredlogs, black, pycantonese, onnxsim, onnxruntime\n",
            "Successfully installed black-22.3.0 coloredlogs-15.0.1 dill-0.3.8 docopt-0.6.2 flake8-5.0.4 humanfriendly-10.0 isort-5.10.1 kaldi-decoder-0.2.5 kaldialign-0.9.1 kaldifst-1.7.10 kaldilm-1.15.1 mccabe-0.7.0 mypy-extensions-1.0.0 num2words-0.5.13 onnx-1.16.0 onnxoptimizer-0.3.13 onnxruntime-1.17.3 onnxsim-0.4.36 pathspec-0.12.1 pycantonese-3.4.0 pycodestyle-2.9.1 pyflakes-2.5.0 pylangacq-0.16.2 pypinyin-0.50.0 typeguard-4.2.1 wordseg-0.0.2\n"
          ]
        }
      ],
      "source": [
        "! cd icefall && \\\n",
        "  pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeFyXWEOT4Mi"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqMH7ZLKT8jM"
      },
      "source": [
        "We have set up the environment. Now it is the time to prepare data for training and decoding.\n",
        "\n",
        "As we just said, `icefall` is a collection of Python scripts and we have to set up the `PYTHONPATH` variable to use it. Remember that `icefall` was downloaded to\n",
        "`/content/icefall`, so we use\n",
        "\n",
        "```\n",
        "export PYTHONPATH=/content/icefall:$PYTHONPATH\n",
        "```\n",
        "\n",
        "**HINT**: You can have several versions of `icefall` in your virtual environemnt. To switch to a specific version of `icefall`, just change the `PYTHONPATH` environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YQUEXWruxFu",
        "outputId": "0a6acc70-8933-443c-e603-7e6389d6b77e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: tensorflow 2.15.0\n",
            "Uninstalling tensorflow-2.15.0:\n",
            "  Successfully uninstalled tensorflow-2.15.0\n"
          ]
        }
      ],
      "source": [
        "# To remove the following warning message\n",
        "# 2023-07-27 05:03:07.156920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
        "! pip uninstall -y tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzyw8VyfUjUB",
        "outputId": "1e2ea8ce-3b29-456a-a0f7-d9a3e7d53332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-14 11:35:30 (prepare.sh:27:main) dl_dir: /content/icefall/egs/yesno/ASR/download\n",
            "2024-04-14 11:35:30 (prepare.sh:30:main) Stage 0: Download data\n",
            "/content/icefall/egs/yesno/ASR/download/waves_yesno.tar.gz: 100% 4.70M/4.70M [00:00<00:00, 42.1MB/s]\n",
            "2024-04-14 11:35:33 (prepare.sh:39:main) Stage 1: Prepare yesno manifest\n",
            "2024-04-14 11:35:37 (prepare.sh:45:main) Stage 2: Compute fbank for yesno\n",
            "2024-04-14 11:35:43,568 INFO [compute_fbank_yesno.py:65] Processing train\n",
            "Extracting and storing features: 100% 90/90 [00:00<00:00, 172.64it/s]\n",
            "2024-04-14 11:35:44,114 INFO [compute_fbank_yesno.py:65] Processing test\n",
            "Extracting and storing features: 100% 30/30 [00:00<00:00, 298.40it/s]\n",
            "2024-04-14 11:35:45 (prepare.sh:51:main) Stage 3: Prepare lang\n",
            "2024-04-14 11:35:50,878 INFO [prepare_lang_fst.py:174] Building standard CTC topology\n",
            "2024-04-14 11:35:50,879 INFO [prepare_lang_fst.py:183] Building L\n",
            "2024-04-14 11:35:50,879 INFO [prepare_lang_fst.py:191] Building HL\n",
            "2024-04-14 11:35:50,880 INFO [prepare_lang_fst.py:201] Skip building HLG\n",
            "2024-04-14 11:35:51 (prepare.sh:67:main) Stage 4: Prepare G\n",
            "/project/kaldilm/csrc/arpa_file_parser.cc:void kaldilm::ArpaFileParser::Read(std::istream&):79\n",
            "[I] Reading \\data\\ section.\n",
            "/project/kaldilm/csrc/arpa_file_parser.cc:void kaldilm::ArpaFileParser::Read(std::istream&):140\n",
            "[I] Reading \\1-grams: section.\n",
            "2024-04-14 11:35:51 (prepare.sh:93:main) Stage 5: Compile HLG\n",
            "2024-04-14 11:35:55,297 INFO [compile_hlg.py:124] Processing data/lang_phone\n",
            "2024-04-14 11:35:55,297 INFO [lexicon.py:171] Converting L.pt to Linv.pt\n",
            "2024-04-14 11:35:55,300 INFO [compile_hlg.py:48] Building ctc_topo. max_token_id: 3\n",
            "2024-04-14 11:35:55,301 INFO [compile_hlg.py:52] Loading G.fst.txt\n",
            "2024-04-14 11:35:55,301 INFO [compile_hlg.py:62] Intersecting L and G\n",
            "2024-04-14 11:35:55,303 INFO [compile_hlg.py:64] LG shape: (4, None)\n",
            "2024-04-14 11:35:55,303 INFO [compile_hlg.py:66] Connecting LG\n",
            "2024-04-14 11:35:55,303 INFO [compile_hlg.py:68] LG shape after k2.connect: (4, None)\n",
            "2024-04-14 11:35:55,303 INFO [compile_hlg.py:70] <class 'torch.Tensor'>\n",
            "2024-04-14 11:35:55,303 INFO [compile_hlg.py:71] Determinizing LG\n",
            "2024-04-14 11:35:55,305 INFO [compile_hlg.py:74] <class '_k2.ragged.RaggedTensor'>\n",
            "2024-04-14 11:35:55,305 INFO [compile_hlg.py:76] Connecting LG after k2.determinize\n",
            "2024-04-14 11:35:55,305 INFO [compile_hlg.py:79] Removing disambiguation symbols on LG\n",
            "2024-04-14 11:35:55,305 INFO [compile_hlg.py:91] LG shape after k2.remove_epsilon: (6, None)\n",
            "2024-04-14 11:35:55,306 INFO [compile_hlg.py:96] Arc sorting LG\n",
            "2024-04-14 11:35:55,306 INFO [compile_hlg.py:99] Composing H and LG\n",
            "2024-04-14 11:35:55,307 INFO [compile_hlg.py:106] Connecting LG\n",
            "2024-04-14 11:35:55,307 INFO [compile_hlg.py:109] Arc sorting LG\n",
            "2024-04-14 11:35:55,307 INFO [compile_hlg.py:111] HLG.shape: (8, None)\n",
            "2024-04-14 11:35:55,307 INFO [compile_hlg.py:127] Saving HLG.pt to data/lang_phone\n"
          ]
        }
      ],
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  rm -rf data && \\\n",
        "  ./prepare.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RAnFhhqZgPo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1phegInRZkbl",
        "outputId": "14f61bf0-b41b-475f-a94f-ac206169342a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-14 11:45:36,621 INFO [train.py:481] Training started\n",
            "2024-04-14 11:45:36,621 INFO [train.py:482] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'lr': 0.01, 'feature_dim': 23, 'weight_decay': 1e-06, 'start_epoch': 0, 'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 10, 'reset_interval': 20, 'valid_interval': 10, 'beam_size': 10, 'reduction': 'sum', 'use_double_scores': True, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 15, 'seed': 42, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.23.0.dev+git.1b68036.clean', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.1', 'icefall-git-branch': 'master', 'icefall-git-sha1': 'ed6bc200-clean', 'icefall-git-date': 'Thu Apr 11 11:35:25 2024', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': '9eed50c84752', 'IP address': '172.28.0.12'}}\n",
            "2024-04-14 11:45:36,623 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n",
            "2024-04-14 11:45:36,624 INFO [train.py:495] device: cuda:0\n",
            "2024-04-14 11:45:37,457 INFO [asr_datamodule.py:146] About to get train cuts\n",
            "2024-04-14 11:45:37,457 INFO [asr_datamodule.py:247] About to get train cuts\n",
            "2024-04-14 11:45:37,612 INFO [asr_datamodule.py:149] About to create train dataset\n",
            "2024-04-14 11:45:37,612 INFO [asr_datamodule.py:201] Using SimpleCutSampler.\n",
            "2024-04-14 11:45:37,612 INFO [asr_datamodule.py:207] About to create train dataloader\n",
            "2024-04-14 11:45:37,613 INFO [asr_datamodule.py:220] About to get test cuts\n",
            "2024-04-14 11:45:37,613 INFO [asr_datamodule.py:255] About to get test cuts\n",
            "2024-04-14 11:45:38,698 INFO [train.py:422] Epoch 0, batch 0, loss[loss=1.065, over 2436.00 frames. ], tot_loss[loss=1.065, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:39,280 INFO [train.py:422] Epoch 0, batch 10, loss[loss=0.4555, over 2828.00 frames. ], tot_loss[loss=0.7082, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:39,780 INFO [train.py:444] Epoch 0, validation loss=0.9047, over 18067.00 frames. \n",
            "2024-04-14 11:45:40,295 INFO [train.py:422] Epoch 0, batch 20, loss[loss=0.2491, over 2695.00 frames. ], tot_loss[loss=0.4791, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:40,652 INFO [train.py:444] Epoch 0, validation loss=0.503, over 18067.00 frames. \n",
            "2024-04-14 11:45:40,702 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-0.pt\n",
            "2024-04-14 11:45:40,771 INFO [train.py:422] Epoch 1, batch 0, loss[loss=0.2489, over 2436.00 frames. ], tot_loss[loss=0.2489, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:41,250 INFO [train.py:422] Epoch 1, batch 10, loss[loss=0.1131, over 2828.00 frames. ], tot_loss[loss=0.1547, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:41,608 INFO [train.py:444] Epoch 1, validation loss=0.1583, over 18067.00 frames. \n",
            "2024-04-14 11:45:42,056 INFO [train.py:422] Epoch 1, batch 20, loss[loss=0.07254, over 2695.00 frames. ], tot_loss[loss=0.1135, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:42,435 INFO [train.py:444] Epoch 1, validation loss=0.0636, over 18067.00 frames. \n",
            "2024-04-14 11:45:42,507 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-1.pt\n",
            "2024-04-14 11:45:42,613 INFO [train.py:422] Epoch 2, batch 0, loss[loss=0.07247, over 2436.00 frames. ], tot_loss[loss=0.07247, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:43,315 INFO [train.py:422] Epoch 2, batch 10, loss[loss=0.04097, over 2828.00 frames. ], tot_loss[loss=0.05131, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:43,853 INFO [train.py:444] Epoch 2, validation loss=0.04036, over 18067.00 frames. \n",
            "2024-04-14 11:45:44,539 INFO [train.py:422] Epoch 2, batch 20, loss[loss=0.03539, over 2695.00 frames. ], tot_loss[loss=0.04531, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:44,968 INFO [train.py:444] Epoch 2, validation loss=0.03524, over 18067.00 frames. \n",
            "2024-04-14 11:45:45,012 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-2.pt\n",
            "2024-04-14 11:45:45,075 INFO [train.py:422] Epoch 3, batch 0, loss[loss=0.03601, over 2436.00 frames. ], tot_loss[loss=0.03601, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:45,557 INFO [train.py:422] Epoch 3, batch 10, loss[loss=0.02377, over 2828.00 frames. ], tot_loss[loss=0.02849, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:45,908 INFO [train.py:444] Epoch 3, validation loss=0.02833, over 18067.00 frames. \n",
            "2024-04-14 11:45:46,367 INFO [train.py:422] Epoch 3, batch 20, loss[loss=0.02193, over 2695.00 frames. ], tot_loss[loss=0.02698, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:46,725 INFO [train.py:444] Epoch 3, validation loss=0.02327, over 18067.00 frames. \n",
            "2024-04-14 11:45:46,766 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-3.pt\n",
            "2024-04-14 11:45:46,829 INFO [train.py:422] Epoch 4, batch 0, loss[loss=0.02214, over 2436.00 frames. ], tot_loss[loss=0.02214, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:47,312 INFO [train.py:422] Epoch 4, batch 10, loss[loss=0.01583, over 2828.00 frames. ], tot_loss[loss=0.01881, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:47,655 INFO [train.py:444] Epoch 4, validation loss=0.02068, over 18067.00 frames. \n",
            "2024-04-14 11:45:48,123 INFO [train.py:422] Epoch 4, batch 20, loss[loss=0.01761, over 2695.00 frames. ], tot_loss[loss=0.01962, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:48,465 INFO [train.py:444] Epoch 4, validation loss=0.01749, over 18067.00 frames. \n",
            "2024-04-14 11:45:48,510 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-4.pt\n",
            "2024-04-14 11:45:48,576 INFO [train.py:422] Epoch 5, batch 0, loss[loss=0.01665, over 2436.00 frames. ], tot_loss[loss=0.01665, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:49,066 INFO [train.py:422] Epoch 5, batch 10, loss[loss=0.01308, over 2828.00 frames. ], tot_loss[loss=0.01502, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:49,407 INFO [train.py:444] Epoch 5, validation loss=0.01543, over 18067.00 frames. \n",
            "2024-04-14 11:45:49,872 INFO [train.py:422] Epoch 5, batch 20, loss[loss=0.0145, over 2695.00 frames. ], tot_loss[loss=0.01618, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:50,211 INFO [train.py:444] Epoch 5, validation loss=0.01527, over 18067.00 frames. \n",
            "2024-04-14 11:45:50,252 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-5.pt\n",
            "2024-04-14 11:45:50,318 INFO [train.py:422] Epoch 6, batch 0, loss[loss=0.0143, over 2436.00 frames. ], tot_loss[loss=0.0143, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:50,803 INFO [train.py:422] Epoch 6, batch 10, loss[loss=0.0112, over 2828.00 frames. ], tot_loss[loss=0.01283, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:51,144 INFO [train.py:444] Epoch 6, validation loss=0.01436, over 18067.00 frames. \n",
            "2024-04-14 11:45:51,611 INFO [train.py:422] Epoch 6, batch 20, loss[loss=0.01356, over 2695.00 frames. ], tot_loss[loss=0.01392, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:51,965 INFO [train.py:444] Epoch 6, validation loss=0.01364, over 18067.00 frames. \n",
            "2024-04-14 11:45:52,007 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-6.pt\n",
            "2024-04-14 11:45:52,069 INFO [train.py:422] Epoch 7, batch 0, loss[loss=0.01266, over 2436.00 frames. ], tot_loss[loss=0.01266, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:52,554 INFO [train.py:422] Epoch 7, batch 10, loss[loss=0.01046, over 2828.00 frames. ], tot_loss[loss=0.01167, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:52,912 INFO [train.py:444] Epoch 7, validation loss=0.01326, over 18067.00 frames. \n",
            "2024-04-14 11:45:53,386 INFO [train.py:422] Epoch 7, batch 20, loss[loss=0.01281, over 2695.00 frames. ], tot_loss[loss=0.01263, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:53,736 INFO [train.py:444] Epoch 7, validation loss=0.01261, over 18067.00 frames. \n",
            "2024-04-14 11:45:53,777 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-7.pt\n",
            "2024-04-14 11:45:53,843 INFO [train.py:422] Epoch 8, batch 0, loss[loss=0.01202, over 2436.00 frames. ], tot_loss[loss=0.01202, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:54,322 INFO [train.py:422] Epoch 8, batch 10, loss[loss=0.009859, over 2828.00 frames. ], tot_loss[loss=0.01097, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:54,677 INFO [train.py:444] Epoch 8, validation loss=0.01243, over 18067.00 frames. \n",
            "2024-04-14 11:45:55,319 INFO [train.py:422] Epoch 8, batch 20, loss[loss=0.01271, over 2695.00 frames. ], tot_loss[loss=0.01192, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:55,817 INFO [train.py:444] Epoch 8, validation loss=0.01202, over 18067.00 frames. \n",
            "2024-04-14 11:45:55,876 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-8.pt\n",
            "2024-04-14 11:45:55,993 INFO [train.py:422] Epoch 9, batch 0, loss[loss=0.01125, over 2436.00 frames. ], tot_loss[loss=0.01125, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:56,705 INFO [train.py:422] Epoch 9, batch 10, loss[loss=0.009496, over 2828.00 frames. ], tot_loss[loss=0.0105, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:57,213 INFO [train.py:444] Epoch 9, validation loss=0.0123, over 18067.00 frames. \n",
            "2024-04-14 11:45:57,671 INFO [train.py:422] Epoch 9, batch 20, loss[loss=0.01226, over 2695.00 frames. ], tot_loss[loss=0.01154, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:58,019 INFO [train.py:444] Epoch 9, validation loss=0.01185, over 18067.00 frames. \n",
            "2024-04-14 11:45:58,065 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-9.pt\n",
            "2024-04-14 11:45:58,132 INFO [train.py:422] Epoch 10, batch 0, loss[loss=0.01094, over 2436.00 frames. ], tot_loss[loss=0.01094, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:45:58,605 INFO [train.py:422] Epoch 10, batch 10, loss[loss=0.0093, over 2828.00 frames. ], tot_loss[loss=0.01028, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:45:58,960 INFO [train.py:444] Epoch 10, validation loss=0.01193, over 18067.00 frames. \n",
            "2024-04-14 11:45:59,487 INFO [train.py:422] Epoch 10, batch 20, loss[loss=0.01196, over 2695.00 frames. ], tot_loss[loss=0.01141, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:45:59,832 INFO [train.py:444] Epoch 10, validation loss=0.01175, over 18067.00 frames. \n",
            "2024-04-14 11:45:59,875 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-10.pt\n",
            "2024-04-14 11:45:59,939 INFO [train.py:422] Epoch 11, batch 0, loss[loss=0.01076, over 2436.00 frames. ], tot_loss[loss=0.01076, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:46:00,425 INFO [train.py:422] Epoch 11, batch 10, loss[loss=0.009168, over 2828.00 frames. ], tot_loss[loss=0.01013, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:46:00,772 INFO [train.py:444] Epoch 11, validation loss=0.01177, over 18067.00 frames. \n",
            "2024-04-14 11:46:01,236 INFO [train.py:422] Epoch 11, batch 20, loss[loss=0.01188, over 2695.00 frames. ], tot_loss[loss=0.01091, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:46:01,579 INFO [train.py:444] Epoch 11, validation loss=0.01164, over 18067.00 frames. \n",
            "2024-04-14 11:46:01,620 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-11.pt\n",
            "2024-04-14 11:46:01,685 INFO [train.py:422] Epoch 12, batch 0, loss[loss=0.01053, over 2436.00 frames. ], tot_loss[loss=0.01053, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:46:02,174 INFO [train.py:422] Epoch 12, batch 10, loss[loss=0.009088, over 2828.00 frames. ], tot_loss[loss=0.009962, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:46:02,515 INFO [train.py:444] Epoch 12, validation loss=0.01156, over 18067.00 frames. \n",
            "2024-04-14 11:46:02,980 INFO [train.py:422] Epoch 12, batch 20, loss[loss=0.01179, over 2695.00 frames. ], tot_loss[loss=0.0106, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:46:03,334 INFO [train.py:444] Epoch 12, validation loss=0.01208, over 18067.00 frames. \n",
            "2024-04-14 11:46:03,376 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-12.pt\n",
            "2024-04-14 11:46:03,442 INFO [train.py:422] Epoch 13, batch 0, loss[loss=0.01051, over 2436.00 frames. ], tot_loss[loss=0.01051, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:46:03,940 INFO [train.py:422] Epoch 13, batch 10, loss[loss=0.009009, over 2828.00 frames. ], tot_loss[loss=0.009939, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:46:04,294 INFO [train.py:444] Epoch 13, validation loss=0.01179, over 18067.00 frames. \n",
            "2024-04-14 11:46:04,764 INFO [train.py:422] Epoch 13, batch 20, loss[loss=0.01171, over 2695.00 frames. ], tot_loss[loss=0.01057, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:46:05,111 INFO [train.py:444] Epoch 13, validation loss=0.01136, over 18067.00 frames. \n",
            "2024-04-14 11:46:05,152 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-13.pt\n",
            "2024-04-14 11:46:05,219 INFO [train.py:422] Epoch 14, batch 0, loss[loss=0.01043, over 2436.00 frames. ], tot_loss[loss=0.01043, over 2436.00 frames. ], batch size: 4\n",
            "2024-04-14 11:46:05,713 INFO [train.py:422] Epoch 14, batch 10, loss[loss=0.008979, over 2828.00 frames. ], tot_loss[loss=0.009849, over 22192.90 frames. ], batch size: 4\n",
            "2024-04-14 11:46:06,062 INFO [train.py:444] Epoch 14, validation loss=0.01146, over 18067.00 frames. \n",
            "2024-04-14 11:46:06,524 INFO [train.py:422] Epoch 14, batch 20, loss[loss=0.01168, over 2695.00 frames. ], tot_loss[loss=0.01038, over 34971.47 frames. ], batch size: 5\n",
            "2024-04-14 11:46:06,870 INFO [train.py:444] Epoch 14, validation loss=0.01141, over 18067.00 frames. \n",
            "2024-04-14 11:46:06,912 INFO [checkpoint.py:75] Saving checkpoint to tdnn/exp/epoch-14.pt\n",
            "2024-04-14 11:46:06,915 INFO [train.py:555] Done!\n"
          ]
        }
      ],
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/train.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnwI18BKcq6e"
      },
      "source": [
        "## Decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WS-i2RdYzrx",
        "outputId": "1dbf08f3-3702-4f4b-ff8d-b274d89b9b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-14 11:46:14,729 INFO [decode.py:262] Decoding started\n",
            "2024-04-14 11:46:14,729 INFO [decode.py:263] {'exp_dir': PosixPath('tdnn/exp'), 'lang_dir': PosixPath('data/lang_phone'), 'feature_dim': 23, 'search_beam': 20, 'output_beam': 8, 'min_active_states': 30, 'max_active_states': 10000, 'use_double_scores': True, 'epoch': 14, 'avg': 2, 'export': False, 'feature_dir': PosixPath('data/fbank'), 'max_duration': 30.0, 'bucketing_sampler': False, 'num_buckets': 10, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': False, 'return_cuts': True, 'num_workers': 2, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.23.0.dev+git.1b68036.clean', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.1', 'icefall-git-branch': 'master', 'icefall-git-sha1': 'ed6bc200-clean', 'icefall-git-date': 'Thu Apr 11 11:35:25 2024', 'icefall-path': '/content/icefall', 'k2-path': '/usr/local/lib/python3.10/dist-packages/k2/__init__.py', 'lhotse-path': '/usr/local/lib/python3.10/dist-packages/lhotse/__init__.py', 'hostname': '9eed50c84752', 'IP address': '172.28.0.12'}}\n",
            "2024-04-14 11:46:14,729 INFO [lexicon.py:168] Loading pre-compiled data/lang_phone/Linv.pt\n",
            "2024-04-14 11:46:14,731 INFO [decode.py:272] device: cuda:0\n",
            "2024-04-14 11:46:15,590 INFO [decode.py:290] averaging ['tdnn/exp/epoch-13.pt', 'tdnn/exp/epoch-14.pt']\n",
            "2024-04-14 11:46:15,594 INFO [asr_datamodule.py:220] About to get test cuts\n",
            "2024-04-14 11:46:15,594 INFO [asr_datamodule.py:255] About to get test cuts\n",
            "2024-04-14 11:46:16,902 INFO [decode.py:203] batch 0/?, cuts processed until now is 4\n",
            "2024-04-14 11:46:18,596 INFO [decode.py:240] The transcripts are stored in tdnn/exp/recogs-test_set.txt\n",
            "2024-04-14 11:46:18,597 INFO [utils.py:656] [test_set] %WER 0.42% [1 / 240, 0 ins, 1 del, 0 sub ]\n",
            "2024-04-14 11:46:18,599 INFO [decode.py:248] Wrote detailed error stats to tdnn/exp/errs-test_set.txt\n",
            "2024-04-14 11:46:18,599 INFO [decode.py:315] Done!\n"
          ]
        }
      ],
      "source": [
        "! export PYTHONPATH=/content/icefall:$PYTHONPATH && \\\n",
        "  cd /content/icefall/egs/yesno/ASR && \\\n",
        "  ./tdnn/decode.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMENow4cc53b"
      },
      "source": [
        "### Show the decoding result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yQT-VEJc3Xz",
        "outputId": "8f80d3a0-b9ee-4317-a63f-2ef80c1d6837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0_0_0_1_0_0_0_1-0:\tref=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_0_1_0_0_0_1-0:\thyp=['NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_0_0_1_0-1:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_0_1_0-1:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO']\n",
            "0_0_1_0_0_1_1_1-2:\tref=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_0_1_1_1-2:\thyp=['NO', 'NO', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\tref=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_0_1_0_0_1-3:\thyp=['NO', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_0_0_1-4:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES']\n",
            "0_0_1_1_0_1_1_0-5:\tref=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_0_1_1_0-5:\thyp=['NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_0_0_0-6:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\tref=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_0_1_1_1_1_0_0-7:\thyp=['NO', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\tref=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_0_1_0_0-8:\thyp=['NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\tref=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_0_1_0_1_0-9:\thyp=['NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\tref=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_0_0_0_0-10:\thyp=['NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\tref=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_0_1_1_1_0_0-11:\thyp=['NO', 'YES', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO']\n",
            "0_1_1_0_0_1_1_1-12:\tref=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_0_0_1_1_1-12:\thyp=['NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "0_1_1_1_0_0_1_0-13:\tref=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_0_0_1_0-13:\thyp=['NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\tref=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "0_1_1_1_1_0_1_0-14:\thyp=['NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_0_0-15:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO']\n",
            "1_0_0_0_0_0_1_1-16:\tref=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_0_0_0_1_1-16:\thyp=['YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\tref=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_0_1_0_1_1_1-17:\thyp=['YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\tref=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_0_1_1_1-18:\thyp=['YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\tref=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_0_1_1_1_1_0_1-19:\thyp=['YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\tref=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_0_1_1_1-20:\thyp=['YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\tref=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_0_1_0_1_1-21:\thyp=['YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES', 'YES']\n",
            "1_1_0_1_0_1_0_0-22:\tref=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_0_1_0_0-22:\thyp=['YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO', 'NO']\n",
            "1_1_0_1_1_0_0_1-23:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_0_0_1-23:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES']\n",
            "1_1_0_1_1_1_1_0-24:\tref=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_0_1_1_1_1_0-24:\thyp=['YES', 'YES', 'NO', 'YES', 'YES', 'YES', 'YES', 'NO']\n",
            "1_1_1_0_0_1_0_1-25:\tref=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_0_1_0_1-25:\thyp=['YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'YES']\n",
            "1_1_1_0_1_0_1_0-26:\tref=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_0_1_0_1_0-26:\thyp=['YES', 'YES', 'YES', 'NO', 'YES', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\tref=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_0_0_1_0-27:\thyp=['YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_0_0_0-28:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'NO', 'NO', 'NO']\n",
            "1_1_1_1_1_1_1_1-29:\tref=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n",
            "1_1_1_1_1_1_1_1-29:\thyp=['YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES', 'YES']\n"
          ]
        }
      ],
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/recogs-test_set.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RIxtJ-IdLob"
      },
      "source": [
        "### Show the detailed WER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lQFBS-KdIVx",
        "outputId": "f5abb11d-daa4-4c78-f6cf-aaaa19c96df7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%WER = 0.42\n",
            "Errors: 0 insertions, 1 deletions, 0 substitutions, over 240 reference words (239 correct)\n",
            "Search below for sections starting with PER-UTT DETAILS:, SUBSTITUTIONS:, DELETIONS:, INSERTIONS:, PER-WORD STATS:\n",
            "\n",
            "PER-UTT DETAILS: corr or (ref->hyp)  \n",
            "0_0_0_1_0_0_0_1-0:\tNO NO NO YES NO NO NO YES\n",
            "0_0_1_0_0_0_1_0-1:\tNO NO YES NO NO NO YES NO\n",
            "0_0_1_0_0_1_1_1-2:\tNO NO YES NO NO YES YES YES\n",
            "0_0_1_0_1_0_0_1-3:\tNO NO YES NO YES NO NO YES\n",
            "0_0_1_1_0_0_0_1-4:\tNO NO YES YES NO NO NO YES\n",
            "0_0_1_1_0_1_1_0-5:\tNO NO YES YES NO YES YES NO\n",
            "0_0_1_1_1_0_0_0-6:\tNO NO YES YES YES NO NO NO\n",
            "0_0_1_1_1_1_0_0-7:\tNO NO YES YES YES YES NO NO\n",
            "0_1_0_0_0_1_0_0-8:\tNO YES NO NO NO YES NO NO\n",
            "0_1_0_0_1_0_1_0-9:\tNO YES NO NO YES NO YES NO\n",
            "0_1_0_1_0_0_0_0-10:\tNO YES NO YES NO NO NO (NO->*)\n",
            "0_1_0_1_1_1_0_0-11:\tNO YES NO YES YES YES NO NO\n",
            "0_1_1_0_0_1_1_1-12:\tNO YES YES NO NO YES YES YES\n",
            "0_1_1_1_0_0_1_0-13:\tNO YES YES YES NO NO YES NO\n",
            "0_1_1_1_1_0_1_0-14:\tNO YES YES YES YES NO YES NO\n",
            "1_0_0_0_0_0_0_0-15:\tYES NO NO NO NO NO NO NO\n",
            "1_0_0_0_0_0_1_1-16:\tYES NO NO NO NO NO YES YES\n",
            "1_0_0_1_0_1_1_1-17:\tYES NO NO YES NO YES YES YES\n",
            "1_0_1_1_0_1_1_1-18:\tYES NO YES YES NO YES YES YES\n",
            "1_0_1_1_1_1_0_1-19:\tYES NO YES YES YES YES NO YES\n",
            "1_1_0_0_0_1_1_1-20:\tYES YES NO NO NO YES YES YES\n",
            "1_1_0_0_1_0_1_1-21:\tYES YES NO NO YES NO YES YES\n",
            "1_1_0_1_0_1_0_0-22:\tYES YES NO YES NO YES NO NO\n",
            "1_1_0_1_1_0_0_1-23:\tYES YES NO YES YES NO NO YES\n",
            "1_1_0_1_1_1_1_0-24:\tYES YES NO YES YES YES YES NO\n",
            "1_1_1_0_0_1_0_1-25:\tYES YES YES NO NO YES NO YES\n",
            "1_1_1_0_1_0_1_0-26:\tYES YES YES NO YES NO YES NO\n",
            "1_1_1_1_0_0_1_0-27:\tYES YES YES YES NO NO YES NO\n",
            "1_1_1_1_1_0_0_0-28:\tYES YES YES YES YES NO NO NO\n",
            "1_1_1_1_1_1_1_1-29:\tYES YES YES YES YES YES YES YES\n",
            "\n",
            "SUBSTITUTIONS: count ref -> hyp\n",
            "\n",
            "DELETIONS: count ref\n",
            "1   NO\n",
            "\n",
            "INSERTIONS: count hyp\n",
            "\n",
            "PER-WORD STATS: word  corr tot_errs count_in_ref count_in_hyp\n",
            "NO   115 1 116 115\n",
            "YES   124 0 124 124\n"
          ]
        }
      ],
      "source": [
        "! cd /content/icefall/egs/yesno/ASR && \\\n",
        "  cat tdnn/exp/errs-test_set.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
